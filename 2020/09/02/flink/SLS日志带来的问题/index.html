<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="问题描述​    我司的实时计算平台的Flink任务是把日志打到阿里云的日志服务（SLS）上面的，相关基础知识请见参考文档。  ​    在实时计算平台的Flink版本由1.9升级到1.10的过程中，发现某些写HDFS的任务经常重启，查看日志发现是255的问题，详细error日志如下： 1234567891011121314151617181920level: ERRORlog: 2020-09-">
<meta name="keywords" content="Flink问题排查">
<meta property="og:type" content="article">
<meta property="og:title" content="SLS日志带来的问题">
<meta property="og:url" content="http://yoursite.com/2020/09/02/flink/SLS日志带来的问题/index.html">
<meta property="og:site_name" content="纪光的博客">
<meta property="og:description" content="问题描述​    我司的实时计算平台的Flink任务是把日志打到阿里云的日志服务（SLS）上面的，相关基础知识请见参考文档。  ​    在实时计算平台的Flink版本由1.9升级到1.10的过程中，发现某些写HDFS的任务经常重启，查看日志发现是255的问题，详细error日志如下： 1234567891011121314151617181920level: ERRORlog: 2020-09-">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2021-06-20T04:19:35.143Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SLS日志带来的问题">
<meta name="twitter:description" content="问题描述​    我司的实时计算平台的Flink任务是把日志打到阿里云的日志服务（SLS）上面的，相关基础知识请见参考文档。  ​    在实时计算平台的Flink版本由1.9升级到1.10的过程中，发现某些写HDFS的任务经常重启，查看日志发现是255的问题，详细error日志如下： 1234567891011121314151617181920level: ERRORlog: 2020-09-">
  <link rel="canonical" href="http://yoursite.com/2020/09/02/flink/SLS日志带来的问题/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>SLS日志带来的问题 | 纪光的博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?bca403b673d79e83a47dc62fea1dd605";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">纪光的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      
    
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/02/flink/SLS日志带来的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="姜纪光">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="纪光的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            SLS日志带来的问题
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-09-02 10:16:59" itemprop="dateCreated datePublished" datetime="2020-09-02T10:16:59+08:00">2020-09-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-20 12:19:35" itemprop="dateModified" datetime="2021-06-20T12:19:35+08:00">2021-06-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/flink/" itemprop="url" rel="index">
                    <span itemprop="name">flink</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            <span id="/2020/09/02/flink/SLS日志带来的问题/" class="post-meta-item leancloud_visitors" data-flag-title="SLS日志带来的问题" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>​    我司的实时计算平台的Flink任务是把日志打到阿里云的日志服务（SLS）上面的，相关基础知识请见参考文档。 </p>
<p>​    在实时计算平台的Flink版本由1.9升级到1.10的过程中，发现某些写HDFS的任务经常重启，查看日志发现是255的问题，详细error日志如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">level: ERROR</span><br><span class="line">log: 2020-09-02 11:03:35,533 kafka2hive_ireport_jianduoduo_pb2_unfold_testf10 ERROR org.apache.flink.yarn.YarnResourceManager - Closing TaskExecutor connection container_1597847003686_0248_01_000005. Because: Exception from container-launch. Container id: container_1597847003686_0248_01_000005 Exit code: 255 Stack trace: ExitCodeException exitCode=255: at org.apache.hadoop.util.Shell.runCommand(Shell.java:604) at org.apache.hadoop.util.Shell.run(Shell.java:507) at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:789) at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213) at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302) at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Container exited with a non-zero exit code 255</span><br><span class="line">location: org.apache.flink.runtime.resourcemanager.ResourceManager.closeTaskManagerConnection(ResourceManager.java:792)</span><br><span class="line">message: Closing TaskExecutor connection container_1597847003686_0248_01_000005. Because: Exception from container-launch.</span><br><span class="line">Container id: container_1597847003686_0248_01_000005</span><br><span class="line">Exit code: 255</span><br><span class="line">Stack trace: ExitCodeException exitCode=255:</span><br><span class="line">at org.apache.hadoop.util.Shell.runCommand(Shell.java:604)</span><br><span class="line">at org.apache.hadoop.util.Shell.run(Shell.java:507)</span><br><span class="line">at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:789)</span><br><span class="line">at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213)</span><br><span class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)</span><br><span class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">at java.lang.Thread.run(Thread.java:748)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Container exited with a non-zero exit code 255</span><br></pre></td></tr></table></figure>

<p>从上述日志可见，是hadoop抛出的错误，但是对排查任务重启用途不大。</p>
<p>除此之外就是container拒绝连接，原因是 container 被kill 掉。</p>
<p>排查了几天，没有头绪，后来怀疑是否是有日志，但是没有打印出来，所以就在log4j.properties配置文件中，新增了个appender，把日志打印的文件，终于发现了问题，日志如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">2020-09-02 16:07:11,788 ERROR org.apache.flink.runtime.taskmanager.Task                     - Encountered fatal error java.lang.OutOfMemoryError - terminating the JVM</span><br><span class="line">java.lang.OutOfMemoryError: Direct buffer memory. The direct out-of-memory error has occurred. This can mean two things: either job(s) require(s) a larger size of JVM direct memory or there is a direct memory leak. The direct memory can be allocated by user code or some of its dependencies. In this case &apos;taskmanager.memory.task.off-heap.size&apos; configuration option should be increased. Flink framework and its dependencies also consume the direct memory, mostly for network communication. The most of network memory is managed by Flink and should not result in out-of-memory error. In certain special cases, in particular for jobs with high parallelism, the framework may require more direct memory which is not managed by Flink. In this case &apos;taskmanager.memory.framework.off-heap.size&apos; configuration option should be increased. If the error persists then there is probably a direct memory leak which has to be investigated and fixed. The task executor has to be shutdown...</span><br><span class="line">        at java.nio.Bits.reserveMemory(Bits.java:694)</span><br><span class="line">        at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123)</span><br><span class="line">        at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)</span><br><span class="line">        at org.apache.parquet.hadoop.codec.SnappyCompressor.setInput(SnappyCompressor.java:97)</span><br><span class="line">        at org.apache.parquet.hadoop.codec.NonBlockedCompressorStream.write(NonBlockedCompressorStream.java:48)</span><br><span class="line">        at org.apache.parquet.bytes.CapacityByteArrayOutputStream.writeToOutput(CapacityByteArrayOutputStream.java:227)</span><br><span class="line">        at org.apache.parquet.bytes.CapacityByteArrayOutputStream.writeTo(CapacityByteArrayOutputStream.java:249)</span><br><span class="line">        at org.apache.parquet.bytes.BytesInput$CapacityBAOSBytesInput.writeAllTo(BytesInput.java:405)</span><br><span class="line">        at org.apache.parquet.bytes.BytesInput$SequenceBytesIn.writeAllTo(BytesInput.java:296)</span><br><span class="line">        at org.apache.parquet.hadoop.CodecFactory$HeapBytesCompressor.compress(CodecFactory.java:164)</span><br><span class="line">        at org.apache.parquet.hadoop.ColumnChunkPageWriteStore$ColumnChunkPageWriter.writePage(ColumnChunkPageWriteStore.java:95)</span><br><span class="line">        at org.apache.parquet.column.impl.ColumnWriterV1.writePage(ColumnWriterV1.java:147)</span><br><span class="line">        at org.apache.parquet.column.impl.ColumnWriterV1.accountForValueWritten(ColumnWriterV1.java:106)</span><br><span class="line">        at org.apache.parquet.column.impl.ColumnWriterV1.write(ColumnWriterV1.java:200)</span><br><span class="line">        at org.apache.parquet.io.MessageColumnIO$MessageColumnIORecordConsumer.addBinary(MessageColumnIO.java:469)</span><br><span class="line">        at org.apache.parquet.avro.AvroWriteSupport.writeValueWithoutConversion(AvroWriteSupport.java:346)</span><br><span class="line">        at org.apache.parquet.avro.AvroWriteSupport.writeValue(AvroWriteSupport.java:278)</span><br><span class="line">        at org.apache.parquet.avro.AvroWriteSupport.writeRecordFields(AvroWriteSupport.java:191)</span><br><span class="line">        at org.apache.parquet.avro.AvroWriteSupport.write(AvroWriteSupport.java:165)</span><br><span class="line">        at org.apache.parquet.hadoop.InternalParquetRecordWriter.write(InternalParquetRecordWriter.java:128)</span><br><span class="line">        at org.apache.parquet.hadoop.ParquetWriter.write(ParquetWriter.java:299)</span><br><span class="line">        at org.apache.flink.formats.parquet.ParquetBulkWriter.addElement(ParquetBulkWriter.java:52)</span><br><span class="line">        at org.apache.flink.streaming.api.functions.sink.filesystem.BulkPartWriter.write(BulkPartWriter.java:50)</span><br><span class="line">        at org.apache.flink.streaming.api.functions.sink.filesystem.Bucket.write(Bucket.java:214)</span><br><span class="line">        at org.apache.flink.streaming.api.functions.sink.filesystem.Buckets.onElement(Buckets.java:274)</span><br><span class="line">        at org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink.invoke(StreamingFileSink.java:470)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)</span><br><span class="line">        at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)</span><br><span class="line">        at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185)</span><br><span class="line">        at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150)</span><br><span class="line">        at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.runWithPartitionDiscovery(FlinkKafkaConsumerBase.java:728)</span><br><span class="line">        at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:720)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)</span><br><span class="line">        at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)</span><br><span class="line">        at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:200)</span><br></pre></td></tr></table></figure>

<p>很明显，发生了OOM</p>
<h1 id="内存总结"><a href="#内存总结" class="headerlink" title="内存总结"></a>内存总结</h1><p>1、flink1.10和flink1.9的TM都是15360MB，每个TM的slot数是：8</p>
<p>2、根据jmap -heap pid 查看实际的堆的概要</p>
<p>结论：使用CMS垃圾收集时，需要显示设置NewRatio</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">              #Flink1.10     #Flink1.9      #Flink1.10(去掉CMS) #Flink1.10(CMS设置NewRatio)  </span><br><span class="line">MaxHeapSize   7296.0MB       10496.0MB          7296.0MB        7296.0MB</span><br><span class="line">NewSize       332.75MB       3498.5MB           2432.0MB        2432.0MB</span><br><span class="line">MaxNewSize    332.75MB       3498.5MB           2432.0MB        2432.0MB</span><br><span class="line">OldSize       6963.25MB      6997.5MB           4864.0MB        4864.0MB</span><br><span class="line">NewRatio      2              2                  2               2</span><br><span class="line">SurvivorRatio 8              8                  8               8</span><br><span class="line">MetaspaceSize 20.796875MB    20.796875MB        20.796875MB     20.796875MB</span><br><span class="line">CompressedClassSpaceSize 248.0MB 1024.0MB       248.0MB         248.0MB</span><br><span class="line">MaxMetaspaceSize 256.0MB     17592186044415 MB  256.0MB         256.0MB</span><br></pre></td></tr></table></figure>

<h1 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h1><p>​    经过几天的努力，问题是找到了，但是如何解决呢？</p>
<p>既然是SLS的日志没有打印出来，那么首先从日志入手，通过分析源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ProducerBatch类中，日志发送的条件：</span></span><br><span class="line"><span class="comment">//log4j.appender.loghub.batchCountThreshold </span></span><br><span class="line"><span class="comment">//log4j.appender.loghub.batchSizeThresholdInBytes</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isMeetSendCondition</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> curBatchSizeInBytes &gt;= batchSizeThresholdInBytes || curBatchCount &gt;= batchCountThreshold;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>​    可见是要 缓存到达到 条数或者大小的阈值，那么就会发送。但是无论如何配置这两个参数，都不会在sls中打印日志，这个先放一放。</p>
<p>​    既然是Direct buffer memory发生了OOM，那么入手点就从JVM的Direct内存着手吧。</p>
<p>启动命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> 172.16.190.63</span><br><span class="line"> export HADOOP_USER_NAME=qttods</span><br><span class="line"> export HADOOP_CONF_DIR=/etc/apps/hadoop-conf</span><br><span class="line"> export FLINK_HOME=/data/flink/prd/flink-1.10.1-255</span><br><span class="line"> export FLINK_CONF_DIR=/data/flink/prd/flink-1.10.1-255/conf</span><br><span class="line"> </span><br><span class="line"> /data/flink/prd/flink-1.10.1-255/bin/flink run -d -m yarn-cluster -p 40 -yjm 2048 -ytm 15360 -ys 8 -yqu root.data.stream -ynm kafka2hive_ireport_jianduoduo_pb2_unfold_testf10_jiangjiguang -yD metrics.reporter.prom.labels="libra_job_name=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10;libra_job_owner=yanggang@qutoutiao.net,chuyuqiao@qutoutiao.net,liuguiru@qutoutiao.net" -yD env.java.opts="-server -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75 -XX:ParallelGCThreads=4 -XX:+AlwaysPreTouch -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/test-255-01.hprof -Xloggc:/tmp/trace-test-255-01.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -DjobName=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10" -s hdfs://rt2/user/flink/checkpoints/10a74a92f59f091b23bfedc5c5c6211c/chk-707 -c com.innotechx.Pb2UnfoldToHdfsV2 /tmp/aec4472990a347b5a2d279bc90e1551f-15990382903473729850800121691408.jar --jobConfigPath /tmp/aec4472990a347b5a2d279bc90e1551f-1599038298224329812466599395962.properties --job.name kafka2hive_ireport_jianduoduo_pb2_unfold_testf10</span><br><span class="line"> </span><br><span class="line">  /data/flink/prd/flink-1.10.1-255/bin/flink run -d -m yarn-cluster -p 40 -yjm 2048 -ytm 15360 -ys 8 -yqu root.data.stream -ynm kafka2hive_ireport_jianduoduo_pb2_unfold_testf10_jiangjiguang -yD metrics.reporter.prom.labels="libra_job_name=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10;libra_job_owner=yanggang@qutoutiao.net,chuyuqiao@qutoutiao.net,liuguiru@qutoutiao.net" -yD env.java.opts="-server -DjobName=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10" -s hdfs://rt2/user/flink/checkpoints/10a74a92f59f091b23bfedc5c5c6211c/chk-707 -c com.innotechx.Pb2UnfoldToHdfsV2 /tmp/aec4472990a347b5a2d279bc90e1551f-15990382903473729850800121691408.jar --jobConfigPath /tmp/aec4472990a347b5a2d279bc90e1551f-1599038298224329812466599395962.properties --job.name kafka2hive_ireport_jianduoduo_pb2_unfold_testf10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/data/flink/prd/flink-1.10.1-255/bin/flink run -d -m yarn-cluster -p 40 -yjm 2048 -ytm 15360 -ys 8 -yqu root.data.stream -ynm kafka2hive_ireport_jianduoduo_pb2_unfold_testf10_jiangjiguang -yD taskmanager.memory.network.fraction="0.01" -yD taskmanager.memory.managed.fraction="0.1" -yD metrics.reporter.prom.labels="libra_job_name=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10;libra_job_owner=yanggang@qutoutiao.net,chuyuqiao@qutoutiao.net,liuguiru@qutoutiao.net" -yD env.java.opts="-server -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75 -XX:ParallelGCThreads=4 -XX:+AlwaysPreTouch -XX:NewRatio=1 -XX:MaxDirectMemorySize=4g  -XX:MaxMetaspaceSize=1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp -Xloggc:/tmp/trace-test-255-05.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -DjobName=kafka2hive_ireport_jianduoduo_pb2_unfold_testf10" -c com.innotechx.Pb2UnfoldToHdfsV2 /tmp/ec5ae33a1f0442e4bd05ed0db720fdd9-15993772169427635195942810927092.jar --jobConfigPath /tmp/ec5ae33a1f0442e4bd05ed0db720fdd9-15993772187798971639293380321851.properties --job.name kafka2hive_ireport_jianduoduo_pb2_unfold_testf10</span><br></pre></td></tr></table></figure>

<p>查看堆的概要信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>flink1.10</span><br><span class="line"><span class="meta">#</span> jmap -heap 41010</span><br><span class="line">Attaching to process ID 41010, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.212-b10</span><br><span class="line"></span><br><span class="line">using parallel threads in the new generation.</span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Concurrent Mark-Sweep GC</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = 40</span><br><span class="line">   MaxHeapFreeRatio         = 70</span><br><span class="line">   MaxHeapSize              = 7650410496 (7296.0MB)</span><br><span class="line">   NewSize                  = 348913664 (332.75MB)</span><br><span class="line">   MaxNewSize               = 348913664 (332.75MB)</span><br><span class="line">   OldSize                  = 7301496832 (6963.25MB)</span><br><span class="line">   NewRatio                 = 2</span><br><span class="line">   SurvivorRatio            = 8</span><br><span class="line">   MetaspaceSize            = 21807104 (20.796875MB)</span><br><span class="line">   CompressedClassSpaceSize = 260046848 (248.0MB)</span><br><span class="line">   MaxMetaspaceSize         = 268435456 (256.0MB)</span><br><span class="line">   G1HeapRegionSize         = 0 (0.0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">New Generation (Eden + 1 Survivor Space):</span><br><span class="line">   capacity = 314048512 (299.5MB)</span><br><span class="line">   used     = 276619304 (263.80472564697266MB)</span><br><span class="line">   free     = 37429208 (35.695274353027344MB)</span><br><span class="line">   88.08171140132643% used</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = 279183360 (266.25MB)</span><br><span class="line">   used     = 269533872 (257.0475311279297MB)</span><br><span class="line">   free     = 9649488 (9.202468872070312MB)</span><br><span class="line">   96.54367366307218% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = 34865152 (33.25MB)</span><br><span class="line">   used     = 7085432 (6.757194519042969MB)</span><br><span class="line">   free     = 27779720 (26.49280548095703MB)</span><br><span class="line">   20.322389530956297% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = 34865152 (33.25MB)</span><br><span class="line">   used     = 0 (0.0MB)</span><br><span class="line">   free     = 34865152 (33.25MB)</span><br><span class="line">   0.0% used</span><br><span class="line">concurrent mark-sweep generation:</span><br><span class="line">   capacity = 7301496832 (6963.25MB)</span><br><span class="line">   used     = 2099979624 (2002.696632385254MB)</span><br><span class="line">   free     = 5201517208 (4960.553367614746MB)</span><br><span class="line">   28.760946862244698% used</span><br><span class="line"></span><br><span class="line">22116 interned Strings occupying 2178040 bytes.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>flink1.9</span><br><span class="line"><span class="meta">#</span>   jmap -heap 14786</span><br><span class="line">Attaching to process ID 14786, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.212-b10</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with 35 thread(s)</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = 0</span><br><span class="line">   MaxHeapFreeRatio         = 100</span><br><span class="line">   MaxHeapSize              = 11005853696 (10496.0MB)</span><br><span class="line">   NewSize                  = 3668443136 (3498.5MB)</span><br><span class="line">   MaxNewSize               = 3668443136 (3498.5MB)</span><br><span class="line">   OldSize                  = 7337410560 (6997.5MB)</span><br><span class="line">   NewRatio                 = 2</span><br><span class="line">   SurvivorRatio            = 8</span><br><span class="line">   MetaspaceSize            = 21807104 (20.796875MB)</span><br><span class="line">   CompressedClassSpaceSize = 1073741824 (1024.0MB)</span><br><span class="line">   MaxMetaspaceSize         = 17592186044415 MB</span><br><span class="line">   G1HeapRegionSize         = 0 (0.0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = 3603955712 (3437.0MB)</span><br><span class="line">   used     = 1283197528 (1223.7525253295898MB)</span><br><span class="line">   free     = 2320758184 (2213.24747467041MB)</span><br><span class="line">   35.60525240993861% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = 33030144 (31.5MB)</span><br><span class="line">   used     = 10240816 (9.766403198242188MB)</span><br><span class="line">   free     = 22789328 (21.733596801757812MB)</span><br><span class="line">   31.004454597594247% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = 31457280 (30.0MB)</span><br><span class="line">   used     = 0 (0.0MB)</span><br><span class="line">   free     = 31457280 (30.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity = 7337410560 (6997.5MB)</span><br><span class="line">   used     = 4636194168 (4421.419303894043MB)</span><br><span class="line">   free     = 2701216392 (2576.080696105957MB)</span><br><span class="line">   63.18569923392702% used</span><br><span class="line"></span><br><span class="line">21238 interned Strings occupying 2216688 bytes.</span><br></pre></td></tr></table></figure>

<p>gc分析：几个不同的地方</p>
<p>1.flink1.10的ygc次数是 flink1.9的10倍</p>
<p>2.flink1.10的fgc次数 是 flink1.9的3倍，并且每次都是两次</p>
<p>3.老年代的内存差不多，但是年轻代差了一半</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>flink1.10</span><br><span class="line"><span class="meta">#</span> jstat -gc 44792  30000 3000</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line">34048.0 34048.0  0.0   17960.2 272640.0   0.0    7130368.0  5053278.6  76692.0 73508.0 9676.0 8905.5   2853   56.498   6      0.161   56.659</span><br><span class="line">34048.0 34048.0 29066.3  0.0   272640.0   0.0    7130368.0  5156786.1  76692.0 73573.4 9676.0 8905.5   2946   57.906   6      0.161   58.067</span><br><span class="line">34048.0 34048.0 5823.6  0.0   272640.0 61497.6  7130368.0  5312845.3  76692.0 73580.0 9676.0 8905.5   3042   59.386   6      0.161   59.546</span><br><span class="line">34048.0 34048.0 2743.9  0.0   272640.0 103719.7 7130368.0  2150314.5  76692.0 73569.3 9676.0 8903.2   3136   60.875   8      0.230   61.105</span><br><span class="line">34048.0 34048.0  0.0   19973.2 272640.0 31938.8  7130368.0  2283274.4  76692.0 73569.3 9676.0 8903.2   3233   62.464   8      0.230   62.694</span><br><span class="line"> 34048.0 34048.0 2413.5  0.0   272640.0 190768.7 7130368.0  2357924.5  76948.0 73585.4 9676.0 8903.2   3330   63.882   8      0.230   64.112</span><br><span class="line">34048.0 34048.0 9923.9  0.0   272640.0 30765.9  7130368.0  2431965.7  76948.0 73586.8 9676.0 8903.2   3426   65.261   8      0.230   65.491</span><br><span class="line">34048.0 34048.0 20364.2  0.0   272640.0 168196.2 7130368.0  2503354.2  76948.0 73591.6 9676.0 8903.2   3522   66.737   8      0.230   66.967</span><br><span class="line">34048.0 34048.0 3730.0  0.0   272640.0 151194.1 7130368.0  2757946.3  76948.0 73601.7 9676.0 8904.7   3622   68.301   8      0.230   68.531</span><br><span class="line">34048.0 34048.0 11419.4  0.0   272640.0 107408.4 7130368.0  2856088.4  76948.0 73629.0 9676.0 8906.8   3712   69.647   8      0.230   69.877</span><br><span class="line">34048.0 34048.0 24781.5  0.0   272640.0 97438.2  7130368.0  3489299.4  76948.0 73674.3 9676.0 8908.4   3790   71.381   8      0.230   71.611</span><br><span class="line"> 34048.0 34048.0  0.0   23643.2 272640.0 168464.9 7130368.0  3965166.5  76948.0 73683.1 9676.0 8908.4   3915   74.000   8      0.230   74.230</span><br><span class="line">34048.0 34048.0  0.0   20655.7 272640.0 156331.2 7130368.0  4294415.6  76948.0 73694.9 9676.0 8908.9   4011   76.086   8      0.230   76.316</span><br><span class="line">34048.0 34048.0 15995.2  0.0   272640.0 61402.7  7130368.0  4462356.8  76948.0 73698.4 9676.0 8908.9   4108   78.165   8      0.230   78.395</span><br><span class="line">34048.0 34048.0  0.0   12337.9 272640.0 155669.1 7130368.0  4659455.5  76948.0 73700.0 9676.0 8908.9   4203   80.216   8      0.230   80.446</span><br><span class="line">34048.0 34048.0 5241.2  0.0   272640.0 131752.0 7130368.0  4952546.0  76948.0 73705.0 9676.0 8908.9   4302   82.322   8      0.230   82.552</span><br><span class="line"> 34048.0 34048.0 17571.9  0.0   272640.0 199313.0 7130368.0  5051570.2  76948.0 73710.2 9676.0 8908.9   4398   84.150   8      0.230   84.380</span><br><span class="line">34048.0 34048.0 6498.2  0.0   272640.0 52199.4  7130368.0  5104519.7  76948.0 73721.0 9676.0 8908.9   4496   85.667   8      0.230   85.897</span><br><span class="line">34048.0 34048.0 9111.9  0.0   272640.0 38502.6  7130368.0  5172029.1  76948.0 73735.4 9676.0 8908.9   4594   87.188   8      0.230   87.418</span><br><span class="line">34048.0 34048.0  0.0   18352.7 272640.0 43228.2  7130368.0  5284339.2  76948.0 73756.2 9676.0 8909.9   4689   88.728   8      0.230   88.958</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>flink1.9</span><br><span class="line"><span class="meta">#</span> jstat -gc 14786 30000 3000</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line">45568.0 47616.0  0.0   12921.6 3484672.0 2503523.4 7165440.0  6326798.3  76464.0 73754.2 9392.0 8768.5 214470 3705.983  913   614.443 4320.426</span><br><span class="line">37888.0 37888.0 20193.8  0.0   3506688.0 3372237.9 7165440.0  6387704.6  76464.0 73754.2 9392.0 8768.5 214477 3706.050  913   614.443 4320.493</span><br><span class="line">31232.0 53760.0 31217.9  0.0   3474944.0 1101194.8 7165440.0  6523655.9  76464.0 73754.2 9392.0 8768.5 214485 3706.147  913   614.443 4320.590</span><br><span class="line">60928.0 62976.0  0.0   5540.4 3454976.0 2470735.1 7165440.0  6662801.3  76464.0 73754.2 9392.0 8768.5 214492 3706.219  913   614.443 4320.663</span><br><span class="line">47104.0 48128.0  0.0   7847.3 3483648.0 1235129.2 7165440.0  6788503.2  76464.0 73754.2 9392.0 8768.5 214500 3706.327  913   614.443 4320.770</span><br><span class="line">38400.0 36352.0 17337.3  0.0   3507712.0 3118907.9 7165440.0  6878117.3  76464.0 73754.2 9392.0 8768.5 214507 3706.393  913   614.443 4320.837</span><br><span class="line"> 30208.0 30208.0 4506.1  0.0   3522048.0 1054246.7 7165440.0  6953671.1  76464.0 73754.2 9392.0 8768.5 214515 3706.469  913   614.443 4320.912</span><br><span class="line">29184.0 30208.0  0.0   14626.4 3522048.0 2415288.5 7165440.0  7021759.4  76464.0 73754.2 9392.0 8768.5 214522 3706.536  913   614.443 4320.980</span><br><span class="line">44032.0 44544.0  0.0   4688.7 3493376.0 1107967.4 7165440.0  2424117.6  76464.0 73754.2 9392.0 8768.5 214530 3706.615  914   615.339 4321.954</span><br><span class="line">62976.0 61952.0 5851.1  0.0   3457536.0 3101201.1 7165440.0  2603456.1  76464.0 73754.2 9392.0 8768.5 214537 3706.674  914   615.339 4322.013</span><br><span class="line">47616.0 48640.0  0.0   22723.4 3484672.0 1595221.5 7165440.0  2682181.4  76464.0 73754.2 9392.0 8768.5 214544 3706.715  914   615.339 4322.054</span><br><span class="line"> 135680.0 143360.0  0.0   44444.4 3287552.0 1823553.8 7165440.0  3058429.9  76464.0 73754.2 9392.0 8768.5 214550 3706.810  914   615.339 4322.148</span><br><span class="line">116224.0 114176.0 38072.0  0.0   3352064.0 1633522.4 7165440.0  3630131.4  76464.0 73754.2 9392.0 8768.5 214561 3706.967  914   615.339 4322.306</span><br><span class="line">137216.0 134656.0 19009.1  0.0   3310592.0 2641954.6 7165440.0  3946309.7  76464.0 73754.2 9392.0 8768.5 214569 3707.077  914   615.339 4322.415</span><br><span class="line">106496.0 101888.0 16497.0  0.0   3374080.0 2348381.2 7165440.0  4078682.0  76464.0 73754.2 9392.0 8768.5 214577 3707.168  914   615.339 4322.507</span><br><span class="line">77312.0 75264.0 13088.7  0.0   3429888.0 1659629.8 7165440.0  4281662.3  76464.0 73754.2 9392.0 8768.5 214585 3707.267  914   615.339 4322.606</span><br><span class="line"> 120320.0 117248.0 10710.2  0.0   3344896.0 853387.3 7165440.0  4595702.3  76464.0 73754.2 9392.0 8768.5 214593 3707.378  914   615.339 4322.717</span><br><span class="line">87040.0 84480.0 5025.8  0.0   3410944.0 371810.7 7165440.0  4689140.2  76464.0 73754.2 9392.0 8768.5 214601 3707.449  914   615.339 4322.788</span><br><span class="line">60416.0 62976.0  0.0   21042.2 3452416.0 2314165.5 7165440.0  4736839.7  76464.0 73754.2 9392.0 8768.5 214608 3707.512  914   615.339 4322.851</span><br></pre></td></tr></table></figure>

<p>GC配置参数对比</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>jinfo 14874</span><br><span class="line">						flink1.10		flink1.9  flink1.10</span><br><span class="line">MaxHeapSize				7.125G			10.25G	  12.1G</span><br><span class="line">MaxNewSize				2.375G  		3.4G      6.05G</span><br><span class="line">OldSize					4.75G			6.8G      6.05G</span><br><span class="line">MaxDirectMemorySize		1.125G			4.75G	  4G</span><br><span class="line">CompressedClassSpaceSize 248M			</span><br><span class="line">MaxMetaspaceSize		256M					  1G</span><br><span class="line">pid</span><br></pre></td></tr></table></figure>

<p>di-h4-dn-13.h.ab1.qttsite.net  29166,29200,29210</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://cn.aliyun.com/product/sls" target="_blank" rel="noopener">日志服务（SLS）</a></p>
<p><a href="https://github.com/aliyun/aliyun-log-log4j-appender/blob/master/README_CN.md" target="_blank" rel="noopener">ALIYUN Log4j Appender</a></p>
<p><a href="https://github.com/aliyun/aliyun-log-java-producer" target="_blank" rel="noopener">aliyun-log-java-producer</a></p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Flink问题排查/" rel="tag"># Flink问题排查</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/09/01/flink/Flink源码贡献/" rel="next" title="Flink源码贡献">
                  <i class="fa fa-chevron-left"></i> Flink源码贡献
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/09/02/knowledge/内存探究/" rel="prev" title="内存探究">
                  内存探究 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#问题描述"><span class="nav-number">1.</span> <span class="nav-text">问题描述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内存总结"><span class="nav-number">2.</span> <span class="nav-text">内存总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#解决思路"><span class="nav-number">3.</span> <span class="nav-text">解决思路</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文档"><span class="nav-number">4.</span> <span class="nav-text">参考文档</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">姜纪光</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">158</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">姜纪光</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">
      
    主题 – <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.4.1
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/muse.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'MIQC4jJTknc0hjNXDAiIuQ21-9Nh9j0Va',
    appKey: 'vaiXpSQLLMglwYsVLOBLzck4',
    placeholder: "Just go go",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: 'zh-cn' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
